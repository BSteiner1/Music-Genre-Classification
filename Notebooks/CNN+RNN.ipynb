{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iee6iURXrbZ7"
      },
      "source": [
        "## Notes:\n",
        "- Doesnt appear to be training very well, training acc rises very slowly\n",
        "- Needs to be tuned\n",
        "\n",
        "Again will only run on Colab because of the loop moving memory onto the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRaDx93JVGqd"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E2AykqBVo3V"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ssbu_I1iVp78",
        "outputId": "bbd1af2b-944f-44ed-d99b-cdaea279f2d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ST311-Group-Project'...\n",
            "remote: Enumerating objects: 2199, done.\u001b[K\n",
            "remote: Counting objects: 100% (201/201), done.\u001b[K\n",
            "remote: Compressing objects: 100% (143/143), done.\u001b[K\n",
            "remote: Total 2199 (delta 88), reused 158 (delta 49), pack-reused 1998\u001b[K\n",
            "Receiving objects: 100% (2199/2199), 1.20 GiB | 38.73 MiB/s, done.\n",
            "Resolving deltas: 100% (88/88), done.\n",
            "Updating files: 100% (2021/2021), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone -b @olly-branch \"https://github.com/BSteiner1/ST311-Group-Project/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJfAHd6FVxJa"
      },
      "outputs": [],
      "source": [
        "class_dict = {'blues' : 0,\n",
        "              'classical': 1,\n",
        "              'country': 2,\n",
        "              'disco' : 3,\n",
        "              'hiphop' : 4,\n",
        "              'jazz' : 5,\n",
        "              'metal' : 6,\n",
        "              'pop' : 7,\n",
        "              'reggae': 8,\n",
        "              'rock' : 9    \n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMLlmk5iV0Od"
      },
      "outputs": [],
      "source": [
        "def collect_data():\n",
        "    data = []\n",
        "    # Collect all images from the 10 genres\n",
        "    for genre in os.listdir(\"ST311-Group-Project/Data/images_original\"):\n",
        "        for image in os.listdir(\"ST311-Group-Project/Data/images_original/\" + genre):\n",
        "            image_path = \"ST311-Group-Project/Data/images_original/\" + genre + \"/\" + image\n",
        "            grayscale_img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            grayscale_img = grayscale_img[35:-36:, 54:-43]\n",
        "            grayscale_img = torch.tensor(grayscale_img).to(dtype = torch.float32).clone().detach().requires_grad_(True)  #.requires_grad(True)\n",
        "            #grayscale_img = torch.tensor(grayscale_img, requires_grad=True)\n",
        "            # Splitting each image vertically into 5 different parts\n",
        "            for i in range(5):\n",
        "                # The data loader adds a dimension so I've removed a dimension from the image and class\n",
        "                data.append((grayscale_img[ : ,  (67*i):67*(i+1)].reshape(1,217,67), torch.tensor(class_dict.get(genre)))) #.reshape(1)))\n",
        "            \n",
        "            #data.append((grayscale_img.reshape(1, 217, 335), torch.tensor(class_dict.get(genre))))\n",
        "    return data     \n",
        "\n",
        "data = collect_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sttPP6ebV48l"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.8 * len(data))\n",
        "test_size = len(data) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(data, [train_size, test_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jgL78HlV7A3"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkYtATvzV87e"
      },
      "source": [
        "### CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUZLRjHAV-HT"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Net\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "#Define the net\n",
        "net3 = nn.Sequential(\n",
        "    \n",
        "    #16@3x3 Convolution Layer, Drop-out 0.2\n",
        "    nn.Conv2d(1, 16, kernel_size = 3, stride = 1, padding = \"same\"), nn.Dropout(0.2), nn.ReLU(),\n",
        "\n",
        "    #(2x2) Pooling Layer with stride 2\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "    #32@3x3 Convolution Layer, Drop-out 0.2\n",
        "    nn.Conv2d(16, 32, kernel_size = 3, stride = 1, padding = \"same\"), nn.Dropout(0.2), nn.ReLU(),\n",
        "\n",
        "    #(2x2) Pooling Layer with stride 2\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "    #64@3x3 Convolution Layer, Drop-out 0.2\n",
        "    nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = \"same\"), nn.Dropout(0.2), nn.ReLU(),\n",
        "\n",
        "    #(2x2) Pooling Layer with stride 2\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "    #128@3x3 Convolution Layer, Dropout 0.2\n",
        "    nn.Conv2d(64,128, kernel_size = 3, stride = 1, padding = \"same\"), nn.Dropout(0.2), nn.ReLU(),\n",
        "\n",
        "    #(4x4) Pooling Layer with stride 4\n",
        "    nn.MaxPool2d(kernel_size = 4, stride = 4),\n",
        "\n",
        "    #64@3x3 Convolution Layer, Drop-out 0.2\n",
        "    nn.Conv2d(128, 64, kernel_size = 3, stride = 1, padding = \"same\"), nn.Dropout(0.2), nn.ReLU(),\n",
        "\n",
        "    #Flatten Layer\n",
        "    nn.Flatten(),\n",
        "\n",
        "    #768x384 FC Layer, Drop-out 0.2\n",
        "    nn.Linear(768, 384), nn.Dropout(0.2), nn.ReLU(),\n",
        "\n",
        "    #384x128 FC Layer\n",
        "    nn.Linear(384, 128), nn.ReLU()\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYHBPbT1WEpy"
      },
      "source": [
        "### RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kG_hGfF2WFPZ"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Net\n",
        "'''\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
        "        super(RNNModel, self).__init__()\n",
        "\n",
        "        #Pooling Layer\n",
        "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        #Hidden dimensions\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        #Number of hidden layers\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        #RNN Layer \n",
        "        self.rnn = nn.GRU(input_dim, hidden_dim, layer_dim, batch_first=True, bidirectional = True)\n",
        "\n",
        "        #Linear Layer\n",
        "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #Initialize hidden state with zeros\n",
        "        # to.('cuda') ensures the hidden and input tensors are GPU\n",
        "\n",
        "        x = self.pool(x)\n",
        "\n",
        "        h0 = torch.zeros(self.layer_dim*2, x.size(0), self.hidden_dim).requires_grad_().to('cuda')\n",
        "\n",
        "        #RNN Foward Step\n",
        "        out, hn = self.rnn(x, h0.detach())\n",
        "\n",
        "        #Clips off final hidden state \n",
        "        out = self.fc(out[:, -1, :]) \n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-Xw0oncWKif"
      },
      "outputs": [],
      "source": [
        "input_dim = 108\n",
        "hidden_dim = 169\n",
        "layer_dim = 2\n",
        "output_dim = 10\n",
        "\n",
        "rnn_model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim).to('cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U4aBLP_WUGa"
      },
      "source": [
        "### Ensemble (Acc. 56%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seR-SSktW3-6"
      },
      "source": [
        "Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIuNf6SDWVLF"
      },
      "outputs": [],
      "source": [
        "class cnn_rnn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(cnn_rnn, self).__init__()\n",
        "\n",
        "        #Net to process images\n",
        "        self.net3 = net3\n",
        "\n",
        "        #Net to process features\n",
        "        self.rnn = rnn_model\n",
        "\n",
        "        self.fc1 = nn.Linear(20, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #Pass image through cnn\n",
        "        out1 = self.net3(x)\n",
        "\n",
        "        #Reshape for RNN\n",
        "        seq_dim = 67\n",
        "        input_dim = 217 \n",
        "\n",
        "        x_rnn = x.view(-1, seq_dim, input_dim).requires_grad_()\n",
        "\n",
        "        #Pass features through rnn\n",
        "        out2 = self.rnn(x_rnn)\n",
        "\n",
        "        #Concatenate\n",
        "        concat = torch.cat((out1, out2), dim = 1)\n",
        "        \n",
        "        #Pass through linear layer\n",
        "        out = self.fc1(concat)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQTQhybyXBjt"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_D2UJaKXCra"
      },
      "outputs": [],
      "source": [
        "#Define instance of ensemble\n",
        "\n",
        "cnn_rnn = cnn_rnn().to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGyXhMj5XIsr"
      },
      "outputs": [],
      "source": [
        "#Define Loss and Optimiser\n",
        "\n",
        "cnn_rnn_optimizer = torch.optim.Adam(cnn_rnn.parameters(), lr=0.001)\n",
        "cnn_rnn_loss = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZZrhS51XoZF"
      },
      "outputs": [],
      "source": [
        "#Define Epochs \n",
        "\n",
        "cnn_rnn_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmMwrzPRajIE"
      },
      "outputs": [],
      "source": [
        "#Main Loop\n",
        "\n",
        "for epoch in range(cnn_rnn_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "      \n",
        "        #Moves inputs to the gpu\n",
        "        inputs = inputs.to('cuda')\n",
        "        targets = targets.to('cuda')\n",
        "\n",
        "        # Zero the gradients\n",
        "        cnn_rnn_optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = cnn_rnn(inputs)\n",
        "        loss = cnn_rnn_loss(outputs, targets)\n",
        "        \n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        cnn_rnn_optimizer.step()\n",
        "        \n",
        "        # Compute running loss and accuracy\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        \n",
        "    # Compute validation loss and accuracy\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "\n",
        "            #Moves inputs to gpu\n",
        "            inputs = inputs.to('cuda')\n",
        "            targets = targets.to('cuda')\n",
        "            \n",
        "            outputs = cnn_rnn(inputs)\n",
        "            loss = cnn_rnn_loss(outputs, targets)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            val_total += targets.size(0)\n",
        "            val_correct += predicted.eq(targets).sum().item()\n",
        "    \n",
        "    # Print epoch statistics\n",
        "    print('Epoch %d: Train Loss: %.3f | Train Acc: %.3f%% | Val Loss: %.3f | Val Acc: %.3f%%'\n",
        "          % (epoch+1, running_loss/len(train_loader), 100*correct/total,\n",
        "             val_loss/len(test_loader), 100*val_correct/val_total))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sequential CNN-RNN (65%)\n"
      ],
      "metadata": {
        "id": "NhEg6Gg6xbzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Net\n",
        "\n",
        "'''\n",
        "\n",
        "#Define the net\n",
        "seq_net3 = nn.Sequential(\n",
        "    \n",
        "    #16@3x3 Convolution Layer, Drop-out 0.2\n",
        "    nn.Conv2d(1, 16, kernel_size = 3, stride = 1, padding = \"same\"), nn.Dropout(0.2), nn.ReLU(),\n",
        "\n",
        "    #(2x2) Pooling Layer with stride 2\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "    #32@3x3 Convolution Layer, Drop-out 0.2\n",
        "    nn.Conv2d(16, 32, kernel_size = 3, stride = 1, padding = \"same\"), nn.Dropout(0.2), nn.ReLU(),\n",
        "\n",
        "    #(2x2) Pooling Layer with stride 2\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "    #64@3x3 Convolution Layer, Drop-out 0.2\n",
        "    nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = \"same\"), nn.Dropout(0.2), nn.ReLU(),\n",
        "\n",
        "    #(2x2) Pooling Layer with stride 2\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "    #128@3x3 Convolution Layer, Dropout 0.2\n",
        "    nn.Conv2d(64,128, kernel_size = 3, stride = 1, padding = \"same\"), nn.Dropout(0.2), nn.ReLU(),\n",
        "\n",
        "    #(4x4) Pooling Layer with stride 4\n",
        "    nn.MaxPool2d(kernel_size = 4, stride = 4),\n",
        "\n",
        "    #64@3x3 Convolution Layer, Drop-out 0.2\n",
        "    nn.Conv2d(128, 64, kernel_size = 3, stride = 1, padding = \"same\"), nn.Dropout(0.2), nn.ReLU(),\n",
        "\n",
        "    #Flatten Layer\n",
        "    nn.Flatten(),\n",
        "\n",
        "    #768x384 FC Layer, Drop-out 0.2\n",
        "    nn.Linear(768, 384), nn.Dropout(0.2), nn.ReLU(),\n",
        "\n",
        "    #384x128 FC Layer\n",
        "    nn.Linear(384, 128), nn.ReLU()\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "56s4kiSIDqTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Net\n",
        "'''\n",
        "\n",
        "class seq_RNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
        "        super(seq_RNNModel, self).__init__()\n",
        "\n",
        "        #Hidden dimensions\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        #Number of hidden layers\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        #Bi-GRU Layer \n",
        "        self.bigru = nn.GRU(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
        "  \n",
        "        #hidden_dim x output_dim Linear Layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #Initialize hidden state with zeros\n",
        "        # to.('cuda') ensures the hidden and input tensors are GPU\n",
        "\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to('cuda')\n",
        "\n",
        "        #RNN Foward Step\n",
        "        out, hn = self.bigru(x, h0.detach())\n",
        "\n",
        "        #Clips off final hidden state \n",
        "        out = self.fc(out[:, -1, :]) \n",
        "\n",
        "        #print(out.size())\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "osb0Z-L1DqEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0mHcly0aks9"
      },
      "outputs": [],
      "source": [
        "class seq_cnn_rnn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(seq_cnn_rnn, self).__init__()\n",
        "\n",
        "        #Net to process images\n",
        "        self.seq_net3 = seq_net3\n",
        "\n",
        "        #Net to process features\n",
        "        self.seq_rnn = seq_rnn_model\n",
        "\n",
        "        #Final (10x10) linear layer\n",
        "        self.fc1 = nn.Linear(10, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #Pass image through cnn\n",
        "        cnn_out = self.seq_net3(x)\n",
        "\n",
        "        #print(x.size())\n",
        "\n",
        "        #Reshape for RNN\n",
        "        seq_dim = 128\n",
        "        input_dim = 1 \n",
        "\n",
        "        cnn_out = cnn_out.view(-1, seq_dim, input_dim).requires_grad_()\n",
        "\n",
        "        #Pass features through rnn\n",
        "        rnn_out = self.seq_rnn(cnn_out)\n",
        "        \n",
        "        #Pass through linear layer\n",
        "        out = self.fc1(rnn_out)\n",
        "\n",
        "        return out\n",
        "\n",
        "#Define RNN Structural Parameters\n",
        "seq_input_dim = 1\n",
        "seq_hidden_dim = 128\n",
        "seq_layer_dim = 3\n",
        "seq_output_dim = 10\n",
        "\n",
        "#Define instance of model\n",
        "seq_rnn_model = seq_RNNModel(seq_input_dim, seq_hidden_dim, seq_layer_dim, seq_output_dim).to('cuda')\n",
        "\n",
        "#Transfer model to GPU\n",
        "seq_cnn_rnn = seq_cnn_rnn().to('cuda')\n",
        "\n",
        "#Define model functions\n",
        "seq_cnn_rnn_optimizer = torch.optim.Adam(seq_cnn_rnn.parameters(), lr=0.0001)\n",
        "seq_cnn_rnn_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "#Define epochs\n",
        "seq_cnn_rnn_epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Main Loop\n",
        "\n",
        "for epoch in range(seq_cnn_rnn_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "      \n",
        "        #Moves inputs to the gpu\n",
        "        inputs = inputs.to('cuda')\n",
        "        targets = targets.to('cuda')\n",
        "\n",
        "        # Zero the gradients\n",
        "        seq_cnn_rnn_optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = seq_cnn_rnn(inputs)\n",
        "        loss = seq_cnn_rnn_loss(outputs, targets)\n",
        "        \n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        seq_cnn_rnn_optimizer.step()\n",
        "        \n",
        "        # Compute running loss and accuracy\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        \n",
        "    # Compute validation loss and accuracy\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "\n",
        "            #Moves inputs to gpu\n",
        "            inputs = inputs.to('cuda')\n",
        "            targets = targets.to('cuda')\n",
        "            \n",
        "            outputs = seq_cnn_rnn(inputs)\n",
        "            loss = seq_cnn_rnn_loss(outputs, targets)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            val_total += targets.size(0)\n",
        "            val_correct += predicted.eq(targets).sum().item()\n",
        "    \n",
        "    # Print epoch statistics\n",
        "    print('Epoch %d: Train Loss: %.3f | Train Acc: %.3f%% | Val Loss: %.3f | Val Acc: %.3f%%'\n",
        "          % (epoch+1, running_loss/len(train_loader), 100*correct/total,\n",
        "             val_loss/len(test_loader), 100*val_correct/val_total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dG8wwUzq_r_c",
        "outputId": "59fec2a4-3882-4587-ddb9-7f50c751cfa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 2.138 | Train Acc: 17.117% | Val Loss: 2.063 | Val Acc: 20.020%\n",
            "Epoch 2: Train Loss: 1.956 | Train Acc: 25.300% | Val Loss: 1.932 | Val Acc: 26.426%\n",
            "Epoch 3: Train Loss: 1.850 | Train Acc: 29.630% | Val Loss: 1.905 | Val Acc: 27.127%\n",
            "Epoch 4: Train Loss: 1.790 | Train Acc: 31.757% | Val Loss: 1.862 | Val Acc: 29.129%\n",
            "Epoch 5: Train Loss: 1.734 | Train Acc: 36.161% | Val Loss: 1.777 | Val Acc: 33.734%\n",
            "Epoch 6: Train Loss: 1.681 | Train Acc: 38.413% | Val Loss: 1.742 | Val Acc: 34.434%\n",
            "Epoch 7: Train Loss: 1.658 | Train Acc: 38.313% | Val Loss: 1.753 | Val Acc: 34.535%\n",
            "Epoch 8: Train Loss: 1.605 | Train Acc: 41.742% | Val Loss: 1.681 | Val Acc: 37.437%\n",
            "Epoch 9: Train Loss: 1.550 | Train Acc: 44.094% | Val Loss: 1.719 | Val Acc: 35.836%\n",
            "Epoch 10: Train Loss: 1.514 | Train Acc: 44.845% | Val Loss: 1.599 | Val Acc: 41.141%\n",
            "Epoch 11: Train Loss: 1.437 | Train Acc: 48.774% | Val Loss: 1.554 | Val Acc: 44.945%\n",
            "Epoch 12: Train Loss: 1.381 | Train Acc: 53.003% | Val Loss: 1.531 | Val Acc: 45.345%\n",
            "Epoch 13: Train Loss: 1.328 | Train Acc: 55.656% | Val Loss: 1.507 | Val Acc: 46.847%\n",
            "Epoch 14: Train Loss: 1.249 | Train Acc: 57.958% | Val Loss: 1.452 | Val Acc: 47.147%\n",
            "Epoch 15: Train Loss: 1.190 | Train Acc: 59.935% | Val Loss: 1.374 | Val Acc: 52.152%\n",
            "Epoch 16: Train Loss: 1.154 | Train Acc: 62.062% | Val Loss: 1.370 | Val Acc: 52.152%\n",
            "Epoch 17: Train Loss: 1.091 | Train Acc: 63.614% | Val Loss: 1.291 | Val Acc: 54.054%\n",
            "Epoch 18: Train Loss: 1.057 | Train Acc: 64.389% | Val Loss: 1.276 | Val Acc: 56.456%\n",
            "Epoch 19: Train Loss: 0.999 | Train Acc: 66.992% | Val Loss: 1.285 | Val Acc: 55.155%\n",
            "Epoch 20: Train Loss: 0.979 | Train Acc: 67.217% | Val Loss: 1.291 | Val Acc: 57.257%\n",
            "Epoch 21: Train Loss: 0.917 | Train Acc: 70.320% | Val Loss: 1.262 | Val Acc: 58.559%\n",
            "Epoch 22: Train Loss: 0.887 | Train Acc: 71.346% | Val Loss: 1.212 | Val Acc: 59.359%\n",
            "Epoch 23: Train Loss: 0.859 | Train Acc: 72.322% | Val Loss: 1.272 | Val Acc: 59.159%\n",
            "Epoch 24: Train Loss: 0.810 | Train Acc: 73.999% | Val Loss: 1.238 | Val Acc: 59.660%\n",
            "Epoch 25: Train Loss: 0.762 | Train Acc: 75.275% | Val Loss: 1.248 | Val Acc: 59.259%\n",
            "Epoch 26: Train Loss: 0.758 | Train Acc: 75.125% | Val Loss: 1.245 | Val Acc: 61.461%\n",
            "Epoch 27: Train Loss: 0.707 | Train Acc: 77.127% | Val Loss: 1.186 | Val Acc: 62.563%\n",
            "Epoch 28: Train Loss: 0.683 | Train Acc: 77.953% | Val Loss: 1.208 | Val Acc: 61.461%\n",
            "Epoch 29: Train Loss: 0.636 | Train Acc: 79.279% | Val Loss: 1.237 | Val Acc: 61.962%\n",
            "Epoch 30: Train Loss: 0.633 | Train Acc: 79.479% | Val Loss: 1.226 | Val Acc: 62.462%\n",
            "Epoch 31: Train Loss: 0.597 | Train Acc: 80.831% | Val Loss: 1.232 | Val Acc: 61.762%\n",
            "Epoch 32: Train Loss: 0.565 | Train Acc: 81.782% | Val Loss: 1.296 | Val Acc: 61.662%\n",
            "Epoch 33: Train Loss: 0.551 | Train Acc: 82.307% | Val Loss: 1.216 | Val Acc: 63.864%\n",
            "Epoch 34: Train Loss: 0.521 | Train Acc: 82.683% | Val Loss: 1.276 | Val Acc: 61.662%\n",
            "Epoch 35: Train Loss: 0.511 | Train Acc: 84.059% | Val Loss: 1.218 | Val Acc: 64.464%\n",
            "Epoch 36: Train Loss: 0.465 | Train Acc: 85.435% | Val Loss: 1.263 | Val Acc: 62.062%\n",
            "Epoch 37: Train Loss: 0.489 | Train Acc: 84.384% | Val Loss: 1.273 | Val Acc: 62.062%\n",
            "Epoch 38: Train Loss: 0.445 | Train Acc: 85.786% | Val Loss: 1.265 | Val Acc: 64.164%\n",
            "Epoch 39: Train Loss: 0.393 | Train Acc: 87.437% | Val Loss: 1.308 | Val Acc: 62.863%\n",
            "Epoch 40: Train Loss: 0.415 | Train Acc: 86.486% | Val Loss: 1.277 | Val Acc: 64.264%\n",
            "Epoch 41: Train Loss: 0.382 | Train Acc: 87.588% | Val Loss: 1.335 | Val Acc: 63.463%\n",
            "Epoch 42: Train Loss: 0.370 | Train Acc: 88.013% | Val Loss: 1.365 | Val Acc: 62.563%\n",
            "Epoch 43: Train Loss: 0.365 | Train Acc: 88.313% | Val Loss: 1.406 | Val Acc: 62.462%\n",
            "Epoch 44: Train Loss: 0.343 | Train Acc: 88.539% | Val Loss: 1.436 | Val Acc: 61.562%\n",
            "Epoch 45: Train Loss: 0.335 | Train Acc: 89.139% | Val Loss: 1.336 | Val Acc: 64.364%\n",
            "Epoch 46: Train Loss: 0.339 | Train Acc: 89.014% | Val Loss: 1.290 | Val Acc: 65.265%\n",
            "Epoch 47: Train Loss: 0.311 | Train Acc: 89.915% | Val Loss: 1.460 | Val Acc: 63.664%\n",
            "Epoch 48: Train Loss: 0.290 | Train Acc: 90.766% | Val Loss: 1.331 | Val Acc: 63.764%\n",
            "Epoch 49: Train Loss: 0.312 | Train Acc: 89.790% | Val Loss: 1.415 | Val Acc: 62.963%\n",
            "Epoch 50: Train Loss: 0.264 | Train Acc: 91.692% | Val Loss: 1.452 | Val Acc: 64.064%\n",
            "Epoch 51: Train Loss: 0.267 | Train Acc: 91.466% | Val Loss: 1.411 | Val Acc: 65.966%\n",
            "Epoch 52: Train Loss: 0.264 | Train Acc: 91.266% | Val Loss: 1.411 | Val Acc: 63.564%\n",
            "Epoch 53: Train Loss: 0.229 | Train Acc: 93.018% | Val Loss: 1.445 | Val Acc: 64.865%\n",
            "Epoch 54: Train Loss: 0.250 | Train Acc: 91.692% | Val Loss: 1.330 | Val Acc: 66.867%\n",
            "Epoch 55: Train Loss: 0.216 | Train Acc: 93.519% | Val Loss: 1.421 | Val Acc: 65.566%\n",
            "Epoch 56: Train Loss: 0.213 | Train Acc: 93.569% | Val Loss: 1.451 | Val Acc: 67.067%\n",
            "Epoch 57: Train Loss: 0.208 | Train Acc: 93.018% | Val Loss: 1.498 | Val Acc: 65.666%\n",
            "Epoch 58: Train Loss: 0.201 | Train Acc: 93.544% | Val Loss: 1.455 | Val Acc: 67.167%\n",
            "Epoch 59: Train Loss: 0.198 | Train Acc: 93.669% | Val Loss: 1.486 | Val Acc: 63.664%\n",
            "Epoch 60: Train Loss: 0.218 | Train Acc: 93.193% | Val Loss: 1.465 | Val Acc: 65.866%\n",
            "Epoch 61: Train Loss: 0.186 | Train Acc: 94.169% | Val Loss: 1.524 | Val Acc: 63.964%\n",
            "Epoch 62: Train Loss: 0.177 | Train Acc: 94.144% | Val Loss: 1.476 | Val Acc: 65.566%\n",
            "Epoch 63: Train Loss: 0.167 | Train Acc: 94.995% | Val Loss: 1.528 | Val Acc: 65.165%\n",
            "Epoch 64: Train Loss: 0.195 | Train Acc: 93.794% | Val Loss: 1.500 | Val Acc: 65.165%\n",
            "Epoch 65: Train Loss: 0.175 | Train Acc: 94.720% | Val Loss: 1.497 | Val Acc: 66.667%\n",
            "Epoch 66: Train Loss: 0.178 | Train Acc: 94.369% | Val Loss: 1.515 | Val Acc: 65.666%\n",
            "Epoch 67: Train Loss: 0.151 | Train Acc: 95.195% | Val Loss: 1.477 | Val Acc: 67.467%\n",
            "Epoch 68: Train Loss: 0.144 | Train Acc: 95.721% | Val Loss: 1.446 | Val Acc: 67.968%\n",
            "Epoch 69: Train Loss: 0.163 | Train Acc: 95.245% | Val Loss: 1.475 | Val Acc: 66.166%\n",
            "Epoch 70: Train Loss: 0.171 | Train Acc: 94.469% | Val Loss: 1.631 | Val Acc: 65.766%\n",
            "Epoch 71: Train Loss: 0.144 | Train Acc: 95.445% | Val Loss: 1.592 | Val Acc: 65.365%\n",
            "Epoch 72: Train Loss: 0.160 | Train Acc: 94.645% | Val Loss: 1.547 | Val Acc: 65.666%\n",
            "Epoch 73: Train Loss: 0.135 | Train Acc: 95.546% | Val Loss: 1.533 | Val Acc: 66.066%\n",
            "Epoch 74: Train Loss: 0.133 | Train Acc: 95.746% | Val Loss: 1.549 | Val Acc: 65.566%\n",
            "Epoch 75: Train Loss: 0.127 | Train Acc: 95.946% | Val Loss: 1.572 | Val Acc: 67.067%\n",
            "Epoch 76: Train Loss: 0.114 | Train Acc: 96.697% | Val Loss: 1.583 | Val Acc: 65.766%\n",
            "Epoch 77: Train Loss: 0.168 | Train Acc: 94.520% | Val Loss: 1.651 | Val Acc: 65.165%\n",
            "Epoch 78: Train Loss: 0.116 | Train Acc: 96.271% | Val Loss: 1.519 | Val Acc: 67.167%\n",
            "Epoch 79: Train Loss: 0.122 | Train Acc: 96.121% | Val Loss: 1.639 | Val Acc: 65.966%\n",
            "Epoch 80: Train Loss: 0.145 | Train Acc: 95.270% | Val Loss: 1.573 | Val Acc: 67.167%\n",
            "Epoch 81: Train Loss: 0.108 | Train Acc: 96.872% | Val Loss: 1.644 | Val Acc: 67.367%\n",
            "Epoch 82: Train Loss: 0.097 | Train Acc: 96.822% | Val Loss: 1.652 | Val Acc: 67.067%\n",
            "Epoch 83: Train Loss: 0.120 | Train Acc: 95.921% | Val Loss: 1.771 | Val Acc: 63.463%\n",
            "Epoch 84: Train Loss: 0.134 | Train Acc: 95.746% | Val Loss: 1.579 | Val Acc: 66.266%\n",
            "Epoch 85: Train Loss: 0.106 | Train Acc: 96.572% | Val Loss: 1.605 | Val Acc: 68.068%\n",
            "Epoch 86: Train Loss: 0.101 | Train Acc: 96.822% | Val Loss: 1.707 | Val Acc: 66.466%\n",
            "Epoch 87: Train Loss: 0.103 | Train Acc: 96.647% | Val Loss: 1.672 | Val Acc: 66.066%\n",
            "Epoch 88: Train Loss: 0.119 | Train Acc: 96.096% | Val Loss: 1.622 | Val Acc: 68.869%\n",
            "Epoch 89: Train Loss: 0.090 | Train Acc: 96.997% | Val Loss: 1.663 | Val Acc: 66.967%\n",
            "Epoch 90: Train Loss: 0.089 | Train Acc: 96.872% | Val Loss: 1.630 | Val Acc: 67.167%\n",
            "Epoch 91: Train Loss: 0.096 | Train Acc: 97.147% | Val Loss: 1.709 | Val Acc: 68.068%\n",
            "Epoch 92: Train Loss: 0.089 | Train Acc: 96.997% | Val Loss: 1.580 | Val Acc: 68.669%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-82b8276b3dae>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Backward pass and optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mseq_cnn_rnn_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Compute running loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m                                                f\"but got {result}.\")\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 state_steps)\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    282\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    503\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq_sqrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                 \u001b[0mexp_avg_sq_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_sqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_exp_avg_sqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_div_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq_sqrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq_sqrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "VwHiC0QZ_tRm",
        "outputId": "b0977364-5906-41a2-ef7b-8a4fb468593b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-204-f43c9ff579a5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m108\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 108, 33]' is invalid for input of size 232624"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WYqOXuTPACgf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}