{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iee6iURXrbZ7"
      },
      "source": [
        "## Notes:\n",
        "- Doesnt appear to be training very well, training acc rises very slowly\n",
        "- Needs to be tuned\n",
        "\n",
        "Again will only run on Colab because of the loop moving memory onto the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRaDx93JVGqd"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E2AykqBVo3V"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ssbu_I1iVp78",
        "outputId": "572c538c-76df-43cb-b4ac-4077d54164e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ST311-Group-Project'...\n",
            "remote: Enumerating objects: 2186, done.\u001b[K\n",
            "remote: Counting objects: 100% (188/188), done.\u001b[K\n",
            "remote: Compressing objects: 100% (135/135), done.\u001b[K\n",
            "remote: Total 2186 (delta 83), reused 146 (delta 45), pack-reused 1998\u001b[K\n",
            "Receiving objects: 100% (2186/2186), 1.20 GiB | 38.82 MiB/s, done.\n",
            "Resolving deltas: 100% (83/83), done.\n",
            "Updating files: 100% (2021/2021), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone -b @olly-branch \"https://github.com/BSteiner1/ST311-Group-Project/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJfAHd6FVxJa"
      },
      "outputs": [],
      "source": [
        "class_dict = {'blues' : 0,\n",
        "              'classical': 1,\n",
        "              'country': 2,\n",
        "              'disco' : 3,\n",
        "              'hiphop' : 4,\n",
        "              'jazz' : 5,\n",
        "              'metal' : 6,\n",
        "              'pop' : 7,\n",
        "              'reggae': 8,\n",
        "              'rock' : 9    \n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMLlmk5iV0Od"
      },
      "outputs": [],
      "source": [
        "def collect_data():\n",
        "    data = []\n",
        "    # Collect all images from the 10 genres\n",
        "    for genre in os.listdir(\"ST311-Group-Project/Data/images_original\"):\n",
        "        for image in os.listdir(\"ST311-Group-Project/Data/images_original/\" + genre):\n",
        "            image_path = \"ST311-Group-Project/Data/images_original/\" + genre + \"/\" + image\n",
        "            grayscale_img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            grayscale_img = grayscale_img[35:-36:, 54:-43]\n",
        "            grayscale_img = torch.tensor(grayscale_img).to(dtype = torch.float32).clone().detach().requires_grad_(True)  #.requires_grad(True)\n",
        "            #grayscale_img = torch.tensor(grayscale_img, requires_grad=True)\n",
        "            # Splitting each image vertically into 5 different parts\n",
        "            for i in range(5):\n",
        "                # The data loader adds a dimension so I've removed a dimension from the image and class\n",
        "                data.append((grayscale_img[ : ,  (67*i):67*(i+1)].reshape(1,217,67), torch.tensor(class_dict.get(genre)))) #.reshape(1)))\n",
        "            \n",
        "            #data.append((grayscale_img.reshape(1, 217, 335), torch.tensor(class_dict.get(genre))))\n",
        "    return data     \n",
        "\n",
        "data = collect_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sttPP6ebV48l"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.8 * len(data))\n",
        "test_size = len(data) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(data, [train_size, test_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jgL78HlV7A3"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkYtATvzV87e"
      },
      "source": [
        "### CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUZLRjHAV-HT"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Net\n",
        "\n",
        "'''\n",
        "\n",
        "net3 = nn.Sequential(\n",
        "    \n",
        "    nn.Conv2d(1, 16, kernel_size = 3, stride = 1, padding = \"same\"), nn.ReLU(),\n",
        "\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "    nn.Conv2d(16, 32, kernel_size = 3, stride = 1, padding = \"same\"), nn.ReLU(),\n",
        "\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "    nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = \"same\"), nn.ReLU(),\n",
        "\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "    nn.Conv2d(64,128, kernel_size = 3, stride = 1, padding = \"same\"), nn.ReLU(),\n",
        "\n",
        "    nn.MaxPool2d(kernel_size = 4, stride = 4),\n",
        "\n",
        "    nn.Conv2d(128, 64, kernel_size = 3, stride = 1, padding = \"same\"), nn.ReLU(),\n",
        "\n",
        "    nn.Flatten(),\n",
        "\n",
        "    nn.Linear(768, 384), nn.Dropout(0.2), nn.ReLU(),\n",
        "\n",
        "    nn.Linear(384, 64), nn.Dropout(0.2), nn.ReLU(),\n",
        "\n",
        "    nn.Linear(64,32), nn.Dropout(0.2), nn.ReLU(),\n",
        "\n",
        "    nn.Linear(32,10), nn.ReLU(),\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYHBPbT1WEpy"
      },
      "source": [
        "### RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kG_hGfF2WFPZ"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Parameters\n",
        "'''\n",
        "# batch_size = 20\n",
        "# n_iters = 3000\n",
        "# num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "# num_epochs = int(num_epochs)\n",
        "\n",
        "'''\n",
        "Net\n",
        "'''\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
        "        super(RNNModel, self).__init__()\n",
        "\n",
        "        #Pooling Layer\n",
        "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        #Embedding Layer\n",
        "        #self.embed = nn.Embedding(10, 2)\n",
        "\n",
        "        #Hidden dimensions\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        #Number of hidden layers\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        #RNN Layer \n",
        "        self.rnn = nn.GRU(input_dim, hidden_dim, layer_dim, batch_first=True, bidirectional = True)\n",
        "\n",
        "        #Linear Layer\n",
        "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #Initialize hidden state with zeros\n",
        "        # to.('cuda') ensures the hidden and input tensors are GPU\n",
        "\n",
        "        x = self.pool(x)\n",
        "\n",
        "        #x = self.embed(x)\n",
        "\n",
        "        #print(out.size())\n",
        "\n",
        "        h0 = torch.zeros(self.layer_dim*2, x.size(0), self.hidden_dim).requires_grad_().to('cuda')\n",
        "\n",
        "        #RNN Foward Step\n",
        "        out, hn = self.rnn(x, h0.detach())\n",
        "\n",
        "        #print(out.size())\n",
        "\n",
        "        #Clips off final hidden state \n",
        "        out = self.fc(out[:, -1, :]) \n",
        "\n",
        "        #print(out.size())\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-Xw0oncWKif"
      },
      "outputs": [],
      "source": [
        "input_dim = 108\n",
        "hidden_dim = 169\n",
        "layer_dim = 2\n",
        "output_dim = 10\n",
        "\n",
        "rnn_model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim).to('cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U4aBLP_WUGa"
      },
      "source": [
        "### Ensemble (Acc. 56%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seR-SSktW3-6"
      },
      "source": [
        "Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIuNf6SDWVLF"
      },
      "outputs": [],
      "source": [
        "class cnn_rnn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(cnn_rnn, self).__init__()\n",
        "\n",
        "        #Net to process images\n",
        "        self.net3 = net3\n",
        "\n",
        "        #Net to process features\n",
        "        self.rnn = rnn_model\n",
        "\n",
        "        self.fc1 = nn.Linear(20, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #Pass image through cnn\n",
        "        out1 = self.net3(x)\n",
        "\n",
        "        #print(x.size())\n",
        "\n",
        "        #Reshape for RNN\n",
        "        seq_dim = 67\n",
        "        input_dim = 217 \n",
        "\n",
        "        x_rnn = x.view(-1, seq_dim, input_dim).requires_grad_()\n",
        "\n",
        "        #Pass features through rnn\n",
        "        out2 = self.rnn(x_rnn)\n",
        "\n",
        "        #print(out2.size())\n",
        "\n",
        "        #Concatenate\n",
        "        concat = torch.cat((out1, out2), dim = 1)\n",
        "\n",
        "        #print(concat.size())\n",
        "        \n",
        "        #Pass through linear layer\n",
        "        out = self.fc1(concat)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQTQhybyXBjt"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_D2UJaKXCra"
      },
      "outputs": [],
      "source": [
        "#Define instance of ensemble\n",
        "\n",
        "cnn_rnn = cnn_rnn().to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGyXhMj5XIsr"
      },
      "outputs": [],
      "source": [
        "#Define Loss and Optimiser\n",
        "\n",
        "cnn_rnn_optimizer = torch.optim.Adam(cnn_rnn.parameters(), lr=0.001)\n",
        "cnn_rnn_loss = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZZrhS51XoZF"
      },
      "outputs": [],
      "source": [
        "#Define Epochs \n",
        "\n",
        "cnn_rnn_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmMwrzPRajIE"
      },
      "outputs": [],
      "source": [
        "#Main Loop\n",
        "\n",
        "for epoch in range(cnn_rnn_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "      \n",
        "        #Moves inputs to the gpu\n",
        "        inputs = inputs.to('cuda')\n",
        "        targets = targets.to('cuda')\n",
        "\n",
        "        # Zero the gradients\n",
        "        cnn_rnn_optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = cnn_rnn(inputs)\n",
        "        loss = cnn_rnn_loss(outputs, targets)\n",
        "        \n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        cnn_rnn_optimizer.step()\n",
        "        \n",
        "        # Compute running loss and accuracy\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        \n",
        "    # Compute validation loss and accuracy\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "\n",
        "            #Moves inputs to gpu\n",
        "            inputs = inputs.to('cuda')\n",
        "            targets = targets.to('cuda')\n",
        "            \n",
        "            outputs = cnn_rnn(inputs)\n",
        "            loss = cnn_rnn_loss(outputs, targets)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            val_total += targets.size(0)\n",
        "            val_correct += predicted.eq(targets).sum().item()\n",
        "    \n",
        "    # Print epoch statistics\n",
        "    print('Epoch %d: Train Loss: %.3f | Train Acc: %.3f%% | Val Loss: %.3f | Val Acc: %.3f%%'\n",
        "          % (epoch+1, running_loss/len(train_loader), 100*correct/total,\n",
        "             val_loss/len(test_loader), 100*val_correct/val_total))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sequential CNN-RNN (65%)\n"
      ],
      "metadata": {
        "id": "NhEg6Gg6xbzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Net\n",
        "\n",
        "'''\n",
        "\n",
        "seq_net3 = nn.Sequential(\n",
        "    \n",
        "    nn.Conv2d(1, 16, kernel_size = 3, stride = 1, padding = \"same\"), nn.Dropout(0.2), nn.ReLU(),\n",
        "\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "    nn.Conv2d(16, 32, kernel_size = 3, stride = 1, padding = \"same\"), nn.Dropout(0.2), nn.ReLU(),\n",
        "\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "    nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = \"same\"), nn.Dropout(0.2), nn.ReLU(),\n",
        "\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "    nn.Conv2d(64,128, kernel_size = 3, stride = 1, padding = \"same\"), nn.Dropout(0.2), nn.ReLU(),\n",
        "\n",
        "    nn.MaxPool2d(kernel_size = 4, stride = 4),\n",
        "\n",
        "    nn.Conv2d(128, 64, kernel_size = 3, stride = 1, padding = \"same\"), nn.Dropout(0.2), nn.ReLU(),\n",
        "\n",
        "    nn.Flatten(),\n",
        "\n",
        "    nn.Linear(768, 384), nn.Dropout(0.2), nn.ReLU(),\n",
        "\n",
        "    nn.Linear(384, 128), nn.ReLU()\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "56s4kiSIDqTX"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Net\n",
        "'''\n",
        "\n",
        "class seq_RNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
        "        super(seq_RNNModel, self).__init__()\n",
        "\n",
        "        #Hidden dimensions\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        #Number of hidden layers\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        #GRU 1\n",
        "        #self.gru1 = nn.GRU(input_dim, hidden_dim, layer_dim, batch_first = True)\n",
        "\n",
        "        #Bi-GRU Layer \n",
        "        self.bigru = nn.GRU(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
        "\n",
        "        #GRU 2\n",
        "        #self.gru2 = nn.GRU(input_dim, hidden_dim, layer_dim, batch_first = True)\n",
        "  \n",
        "        #Linear Layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #Initialize hidden state with zeros\n",
        "        # to.('cuda') ensures the hidden and input tensors are GPU\n",
        "\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to('cuda')\n",
        "\n",
        "        #RNN Foward Step\n",
        "        out, hn = self.bigru(x, h0.detach())\n",
        "\n",
        "        #Clips off final hidden state \n",
        "        out = self.fc(out[:, -1, :]) \n",
        "\n",
        "        #print(out.size())\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "osb0Z-L1DqEW"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "h0mHcly0aks9"
      },
      "outputs": [],
      "source": [
        "class seq_cnn_rnn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(seq_cnn_rnn, self).__init__()\n",
        "\n",
        "        #Net to process images\n",
        "        self.seq_net3 = seq_net3\n",
        "\n",
        "        #Net to process features\n",
        "        self.seq_rnn = seq_rnn_model\n",
        "\n",
        "        self.fc1 = nn.Linear(10, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #Pass image through cnn\n",
        "        cnn_out = self.seq_net3(x)\n",
        "\n",
        "        #print(x.size())\n",
        "\n",
        "        #Reshape for RNN\n",
        "        seq_dim = 128\n",
        "        input_dim = 1 \n",
        "\n",
        "        cnn_out = cnn_out.view(-1, seq_dim, input_dim).requires_grad_()\n",
        "\n",
        "        #Pass features through rnn\n",
        "        rnn_out = self.seq_rnn(cnn_out)\n",
        "        \n",
        "        #Pass through linear layer\n",
        "        out = self.fc1(rnn_out)\n",
        "\n",
        "        return out\n",
        "\n",
        "seq_input_dim = 1\n",
        "seq_hidden_dim = 128\n",
        "seq_layer_dim = 4\n",
        "seq_output_dim = 10\n",
        "\n",
        "seq_rnn_model = seq_RNNModel(seq_input_dim, seq_hidden_dim, seq_layer_dim, seq_output_dim).to('cuda')\n",
        "\n",
        "seq_cnn_rnn = seq_cnn_rnn().to('cuda')\n",
        "\n",
        "seq_cnn_rnn_optimizer = torch.optim.Adam(seq_cnn_rnn.parameters(), lr=0.0001)\n",
        "seq_cnn_rnn_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "seq_cnn_rnn_epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Main Loop\n",
        "\n",
        "for epoch in range(seq_cnn_rnn_epochs):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "      \n",
        "        #Moves inputs to the gpu\n",
        "        inputs = inputs.to('cuda')\n",
        "        targets = targets.to('cuda')\n",
        "\n",
        "        # Zero the gradients\n",
        "        seq_cnn_rnn_optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = seq_cnn_rnn(inputs)\n",
        "        loss = seq_cnn_rnn_loss(outputs, targets)\n",
        "        \n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        seq_cnn_rnn_optimizer.step()\n",
        "        \n",
        "        # Compute running loss and accuracy\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        \n",
        "    # Compute validation loss and accuracy\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "\n",
        "            #Moves inputs to gpu\n",
        "            inputs = inputs.to('cuda')\n",
        "            targets = targets.to('cuda')\n",
        "            \n",
        "            outputs = seq_cnn_rnn(inputs)\n",
        "            loss = seq_cnn_rnn_loss(outputs, targets)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            val_total += targets.size(0)\n",
        "            val_correct += predicted.eq(targets).sum().item()\n",
        "    \n",
        "    # Print epoch statistics\n",
        "    print('Epoch %d: Train Loss: %.3f | Train Acc: %.3f%% | Val Loss: %.3f | Val Acc: %.3f%%'\n",
        "          % (epoch+1, running_loss/len(train_loader), 100*correct/total,\n",
        "             val_loss/len(test_loader), 100*val_correct/val_total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dG8wwUzq_r_c",
        "outputId": "0beb26c4-ac92-4c96-efca-18ae82ad5665"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 2.267 | Train Acc: 15.415% | Val Loss: 2.140 | Val Acc: 23.323%\n",
            "Epoch 2: Train Loss: 1.987 | Train Acc: 26.977% | Val Loss: 1.896 | Val Acc: 31.231%\n",
            "Epoch 3: Train Loss: 1.816 | Train Acc: 31.206% | Val Loss: 1.794 | Val Acc: 31.832%\n",
            "Epoch 4: Train Loss: 1.747 | Train Acc: 34.685% | Val Loss: 1.770 | Val Acc: 32.432%\n",
            "Epoch 5: Train Loss: 1.696 | Train Acc: 36.136% | Val Loss: 1.719 | Val Acc: 34.835%\n",
            "Epoch 6: Train Loss: 1.663 | Train Acc: 38.038% | Val Loss: 1.697 | Val Acc: 38.038%\n",
            "Epoch 7: Train Loss: 1.632 | Train Acc: 40.566% | Val Loss: 1.651 | Val Acc: 38.539%\n",
            "Epoch 8: Train Loss: 1.570 | Train Acc: 42.492% | Val Loss: 1.615 | Val Acc: 43.443%\n",
            "Epoch 9: Train Loss: 1.536 | Train Acc: 43.744% | Val Loss: 1.572 | Val Acc: 42.543%\n",
            "Epoch 10: Train Loss: 1.486 | Train Acc: 46.246% | Val Loss: 1.602 | Val Acc: 43.343%\n",
            "Epoch 11: Train Loss: 1.468 | Train Acc: 46.897% | Val Loss: 1.505 | Val Acc: 46.647%\n",
            "Epoch 12: Train Loss: 1.426 | Train Acc: 48.498% | Val Loss: 1.493 | Val Acc: 46.446%\n",
            "Epoch 13: Train Loss: 1.390 | Train Acc: 49.525% | Val Loss: 1.461 | Val Acc: 49.550%\n",
            "Epoch 14: Train Loss: 1.359 | Train Acc: 51.702% | Val Loss: 1.474 | Val Acc: 47.948%\n",
            "Epoch 15: Train Loss: 1.322 | Train Acc: 53.178% | Val Loss: 1.426 | Val Acc: 49.850%\n",
            "Epoch 16: Train Loss: 1.263 | Train Acc: 56.256% | Val Loss: 1.396 | Val Acc: 51.051%\n",
            "Epoch 17: Train Loss: 1.229 | Train Acc: 57.908% | Val Loss: 1.433 | Val Acc: 51.151%\n",
            "Epoch 18: Train Loss: 1.199 | Train Acc: 59.459% | Val Loss: 1.377 | Val Acc: 52.653%\n",
            "Epoch 19: Train Loss: 1.157 | Train Acc: 60.836% | Val Loss: 1.311 | Val Acc: 55.556%\n",
            "Epoch 20: Train Loss: 1.101 | Train Acc: 63.313% | Val Loss: 1.324 | Val Acc: 56.256%\n",
            "Epoch 21: Train Loss: 1.063 | Train Acc: 64.740% | Val Loss: 1.368 | Val Acc: 54.354%\n",
            "Epoch 22: Train Loss: 1.012 | Train Acc: 66.542% | Val Loss: 1.304 | Val Acc: 57.457%\n",
            "Epoch 23: Train Loss: 0.985 | Train Acc: 67.142% | Val Loss: 1.265 | Val Acc: 58.458%\n",
            "Epoch 24: Train Loss: 0.949 | Train Acc: 69.069% | Val Loss: 1.254 | Val Acc: 58.959%\n",
            "Epoch 25: Train Loss: 0.894 | Train Acc: 71.071% | Val Loss: 1.225 | Val Acc: 61.061%\n",
            "Epoch 26: Train Loss: 0.850 | Train Acc: 72.322% | Val Loss: 1.301 | Val Acc: 58.058%\n",
            "Epoch 27: Train Loss: 0.818 | Train Acc: 73.223% | Val Loss: 1.347 | Val Acc: 58.559%\n",
            "Epoch 28: Train Loss: 0.790 | Train Acc: 74.374% | Val Loss: 1.190 | Val Acc: 62.663%\n",
            "Epoch 29: Train Loss: 0.765 | Train Acc: 74.224% | Val Loss: 1.150 | Val Acc: 63.263%\n",
            "Epoch 30: Train Loss: 0.701 | Train Acc: 76.902% | Val Loss: 1.148 | Val Acc: 63.764%\n",
            "Epoch 31: Train Loss: 0.684 | Train Acc: 77.878% | Val Loss: 1.229 | Val Acc: 59.760%\n",
            "Epoch 32: Train Loss: 0.655 | Train Acc: 78.303% | Val Loss: 1.129 | Val Acc: 64.164%\n",
            "Epoch 33: Train Loss: 0.600 | Train Acc: 81.056% | Val Loss: 1.249 | Val Acc: 61.562%\n",
            "Epoch 34: Train Loss: 0.613 | Train Acc: 80.355% | Val Loss: 1.137 | Val Acc: 65.065%\n",
            "Epoch 35: Train Loss: 0.589 | Train Acc: 80.831% | Val Loss: 1.239 | Val Acc: 61.662%\n",
            "Epoch 36: Train Loss: 0.555 | Train Acc: 81.607% | Val Loss: 1.215 | Val Acc: 64.765%\n",
            "Epoch 37: Train Loss: 0.530 | Train Acc: 83.033% | Val Loss: 1.307 | Val Acc: 61.261%\n",
            "Epoch 38: Train Loss: 0.505 | Train Acc: 83.959% | Val Loss: 1.156 | Val Acc: 63.964%\n",
            "Epoch 39: Train Loss: 0.476 | Train Acc: 84.434% | Val Loss: 1.205 | Val Acc: 63.764%\n",
            "Epoch 40: Train Loss: 0.484 | Train Acc: 84.034% | Val Loss: 1.167 | Val Acc: 66.466%\n",
            "Epoch 41: Train Loss: 0.430 | Train Acc: 85.686% | Val Loss: 1.150 | Val Acc: 65.065%\n",
            "Epoch 42: Train Loss: 0.403 | Train Acc: 87.187% | Val Loss: 1.244 | Val Acc: 64.865%\n",
            "Epoch 43: Train Loss: 0.385 | Train Acc: 87.913% | Val Loss: 1.253 | Val Acc: 65.365%\n",
            "Epoch 44: Train Loss: 0.357 | Train Acc: 88.388% | Val Loss: 1.237 | Val Acc: 65.265%\n",
            "Epoch 45: Train Loss: 0.383 | Train Acc: 87.437% | Val Loss: 1.240 | Val Acc: 65.065%\n",
            "Epoch 46: Train Loss: 0.339 | Train Acc: 88.939% | Val Loss: 1.294 | Val Acc: 65.666%\n",
            "Epoch 47: Train Loss: 0.338 | Train Acc: 89.540% | Val Loss: 1.310 | Val Acc: 64.665%\n",
            "Epoch 48: Train Loss: 0.310 | Train Acc: 90.190% | Val Loss: 1.236 | Val Acc: 65.365%\n",
            "Epoch 49: Train Loss: 0.306 | Train Acc: 90.140% | Val Loss: 1.287 | Val Acc: 65.966%\n",
            "Epoch 50: Train Loss: 0.301 | Train Acc: 90.390% | Val Loss: 1.324 | Val Acc: 64.965%\n",
            "Epoch 51: Train Loss: 0.268 | Train Acc: 91.441% | Val Loss: 1.325 | Val Acc: 65.365%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-141-82b8276b3dae>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Backward pass and optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mseq_cnn_rnn_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "VwHiC0QZ_tRm",
        "outputId": "b0977364-5906-41a2-ef7b-8a4fb468593b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-204-f43c9ff579a5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m108\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 108, 33]' is invalid for input of size 232624"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WYqOXuTPACgf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}