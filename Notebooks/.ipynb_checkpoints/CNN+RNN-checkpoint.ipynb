{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "- Doesnt appear to be training very well, training acc rises very slowly\n",
    "- Needs to be tuned\n",
    "\n",
    "Again will only run on Colab because of the loop moving memory onto the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lRaDx93JVGqd"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6E2AykqBVo3V"
   },
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ssbu_I1iVp78",
    "outputId": "a0470152-e1f0-4e2a-d821-be8b27ab86dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ST311-Group-Project'...\n",
      "remote: Enumerating objects: 2139, done.\u001b[K\n",
      "remote: Counting objects: 100% (141/141), done.\u001b[K\n",
      "remote: Compressing objects: 100% (104/104), done.\u001b[K\n",
      "remote: Total 2139 (delta 57), reused 111 (delta 31), pack-reused 1998\u001b[K\n",
      "Receiving objects: 100% (2139/2139), 1.20 GiB | 28.68 MiB/s, done.\n",
      "Resolving deltas: 100% (57/57), done.\n",
      "Updating files: 100% (2015/2015), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone -b @olly-branch \"https://github.com/BSteiner1/ST311-Group-Project/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QJfAHd6FVxJa"
   },
   "outputs": [],
   "source": [
    "class_dict = {'blues' : 0,\n",
    "              'classical': 1,\n",
    "              'country': 2,\n",
    "              'disco' : 3,\n",
    "              'hiphop' : 4,\n",
    "              'jazz' : 5,\n",
    "              'metal' : 6,\n",
    "              'pop' : 7,\n",
    "              'reggae': 8,\n",
    "              'rock' : 9    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TMLlmk5iV0Od"
   },
   "outputs": [],
   "source": [
    "def collect_data():\n",
    "    data = []\n",
    "    # Collect all images from the 10 genres\n",
    "    for genre in os.listdir(\"ST311-Group-Project/Data/images_original\"):\n",
    "        for image in os.listdir(\"ST311-Group-Project/Data/images_original/\" + genre):\n",
    "            image_path = \"ST311-Group-Project/Data/images_original/\" + genre + \"/\" + image\n",
    "            grayscale_img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            grayscale_img = grayscale_img[35:-36:, 54:-43]\n",
    "            grayscale_img = torch.tensor(grayscale_img).to(dtype = torch.float32).clone().detach().requires_grad_(True)  #.requires_grad(True)\n",
    "            #grayscale_img = torch.tensor(grayscale_img, requires_grad=True)\n",
    "            # Splitting each image vertically into 5 different parts\n",
    "            for i in range(5):\n",
    "                # The data loader adds a dimension so I've removed a dimension from the image and class\n",
    "                data.append((grayscale_img[ : ,  (67*i):67*(i+1)].reshape(1,217,67), torch.tensor(class_dict.get(genre)))) #.reshape(1)))\n",
    "            \n",
    "            #data.append((grayscale_img.reshape(1, 217, 335), torch.tensor(class_dict.get(genre))))\n",
    "    return data     \n",
    "\n",
    "data = collect_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sttPP6ebV48l"
   },
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(data))\n",
    "test_size = len(data) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(data, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-jgL78HlV7A3"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkYtATvzV87e"
   },
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "GUZLRjHAV-HT"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Net\n",
    "\n",
    "'''\n",
    "\n",
    "net3 = nn.Sequential(\n",
    "    \n",
    "    nn.Conv2d(1, 16, kernel_size = 3, stride = 1, padding = \"same\"), nn.ReLU(),\n",
    "\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    nn.Conv2d(16, 32, kernel_size = 3, stride = 1, padding = \"same\"), nn.ReLU(),\n",
    "\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = \"same\"), nn.ReLU(),\n",
    "\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    nn.Conv2d(64,128, kernel_size = 3, stride = 1, padding = \"same\"), nn.ReLU(),\n",
    "\n",
    "    nn.MaxPool2d(kernel_size = 4, stride = 4),\n",
    "\n",
    "    nn.Conv2d(128, 64, kernel_size = 3, stride = 1, padding = \"same\"), nn.ReLU(),\n",
    "\n",
    "    nn.Flatten(),\n",
    "\n",
    "    nn.Linear(768, 384), nn.Dropout(0.2), nn.ReLU(),\n",
    "\n",
    "    nn.Linear(384, 64), nn.Dropout(0.2), nn.ReLU(),\n",
    "\n",
    "    nn.Linear(64,32), nn.Dropout(0.2), nn.ReLU(),\n",
    "\n",
    "    nn.Linear(32,10), nn.ReLU(),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYHBPbT1WEpy"
   },
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "kG_hGfF2WFPZ"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Parameters\n",
    "'''\n",
    "# batch_size = 20\n",
    "# n_iters = 3000\n",
    "# num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "# num_epochs = int(num_epochs)\n",
    "\n",
    "'''\n",
    "Net\n",
    "'''\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "\n",
    "        #Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        #Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        #RNN Layer \n",
    "        self.rnn = nn.GRU(input_dim, hidden_dim, layer_dim, batch_first=True, bidirectional = True)\n",
    "\n",
    "        #Linear Layer\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #Initialize hidden state with zeros\n",
    "        # to.('cuda') ensures the hidden and input tensors are GPU\n",
    "\n",
    "        h0 = torch.zeros(self.layer_dim*2, x.size(0), self.hidden_dim).requires_grad_().to('cuda')\n",
    "\n",
    "        #RNN Foward Step\n",
    "        out, hn = self.rnn(x, h0.detach())\n",
    "\n",
    "        #Clips off final hidden state \n",
    "        out = self.fc(out[:, -1, :]) \n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "O-Xw0oncWKif"
   },
   "outputs": [],
   "source": [
    "input_dim = 67\n",
    "hidden_dim = 16\n",
    "layer_dim = 2\n",
    "output_dim = 10\n",
    "\n",
    "rnn_model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim).to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5U4aBLP_WUGa"
   },
   "source": [
    "### Ensemble (Acc. 40%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seR-SSktW3-6"
   },
   "source": [
    "Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "AIuNf6SDWVLF"
   },
   "outputs": [],
   "source": [
    "class cnn_rnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cnn_rnn, self).__init__()\n",
    "\n",
    "        #Net to process images\n",
    "        self.net3 = net3\n",
    "\n",
    "        #Net to process features\n",
    "        self.rnn = rnn_model\n",
    "\n",
    "        self.fc1 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #Pass image through cnn\n",
    "        out1 = self.net3(x)\n",
    "\n",
    "        #print(out1.size())\n",
    "\n",
    "        #Reshape for RNN\n",
    "        seq_dim = 217\n",
    "        input_dim = 67 \n",
    "\n",
    "        x_rnn = x.view(-1, seq_dim, input_dim).requires_grad_()\n",
    "\n",
    "        #Pass features through rnn\n",
    "        out2 = self.rnn(x_rnn)\n",
    "\n",
    "        #print(out2.size())\n",
    "\n",
    "        #Concatenate\n",
    "        concat = torch.cat((out1, out2), dim = 1)\n",
    "\n",
    "        #print(concat.size())\n",
    "        \n",
    "        #Pass through linear layer\n",
    "        out = self.fc1(concat)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQTQhybyXBjt"
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "9_D2UJaKXCra"
   },
   "outputs": [],
   "source": [
    "#Define instance of ensemble\n",
    "\n",
    "cnn_rnn = cnn_rnn().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "yGyXhMj5XIsr"
   },
   "outputs": [],
   "source": [
    "#Define Loss and Optimiser\n",
    "\n",
    "cnn_rnn_optimizer = torch.optim.Adam(cnn_rnn.parameters(), lr=0.01)\n",
    "cnn_rnn_loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "BZZrhS51XoZF"
   },
   "outputs": [],
   "source": [
    "#Define Epochs \n",
    "\n",
    "cnn_rnn_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AmMwrzPRajIE",
    "outputId": "9f02aa15-125b-4009-f0a6-15a4b62ae027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 2.124 | Train Acc: 22.573% | Val Loss: 1.817 | Val Acc: 31.732%\n",
      "Epoch 2: Train Loss: 1.827 | Train Acc: 33.108% | Val Loss: 1.965 | Val Acc: 28.629%\n",
      "Epoch 3: Train Loss: 1.694 | Train Acc: 36.662% | Val Loss: 1.769 | Val Acc: 33.534%\n",
      "Epoch 4: Train Loss: 1.651 | Train Acc: 40.190% | Val Loss: 1.653 | Val Acc: 40.340%\n",
      "Epoch 5: Train Loss: 1.624 | Train Acc: 41.091% | Val Loss: 1.732 | Val Acc: 38.438%\n",
      "Epoch 6: Train Loss: 1.601 | Train Acc: 41.191% | Val Loss: 1.603 | Val Acc: 40.040%\n",
      "Epoch 7: Train Loss: 1.538 | Train Acc: 44.144% | Val Loss: 1.721 | Val Acc: 36.637%\n",
      "Epoch 8: Train Loss: 1.591 | Train Acc: 42.643% | Val Loss: 1.630 | Val Acc: 40.140%\n",
      "Epoch 9: Train Loss: 1.553 | Train Acc: 42.593% | Val Loss: 1.687 | Val Acc: 38.438%\n",
      "Epoch 10: Train Loss: 1.518 | Train Acc: 44.269% | Val Loss: 1.628 | Val Acc: 40.040%\n"
     ]
    }
   ],
   "source": [
    "#Main Loop\n",
    "\n",
    "for epoch in range(cnn_rnn_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "      \n",
    "        #Moves inputs to the gpu\n",
    "        inputs = inputs.to('cuda')\n",
    "        targets = targets.to('cuda')\n",
    "\n",
    "        # Zero the gradients\n",
    "        cnn_rnn_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = cnn_rnn(inputs)\n",
    "        loss = cnn_rnn_loss(outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        cnn_rnn_optimizer.step()\n",
    "        \n",
    "        # Compute running loss and accuracy\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    # Compute validation loss and accuracy\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "\n",
    "            #Moves inputs to gpu\n",
    "            inputs = inputs.to('cuda')\n",
    "            targets = targets.to('cuda')\n",
    "            \n",
    "            outputs = cnn_rnn(inputs)\n",
    "            loss = cnn_rnn_loss(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += targets.size(0)\n",
    "            val_correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    # Print epoch statistics\n",
    "    print('Epoch %d: Train Loss: %.3f | Train Acc: %.3f%% | Val Loss: %.3f | Val Acc: %.3f%%'\n",
    "          % (epoch+1, running_loss/len(train_loader), 100*correct/total,\n",
    "             val_loss/len(test_loader), 100*val_correct/val_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h0mHcly0aks9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
