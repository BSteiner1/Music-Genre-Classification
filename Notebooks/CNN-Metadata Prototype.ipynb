{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ef3f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad9cb04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {'blues' : 0,\n",
    "              'classical': 1,\n",
    "              'country': 2,\n",
    "              'disco' : 3,\n",
    "              'hiphop' : 4,\n",
    "              'jazz' : 5,\n",
    "              'metal' : 6,\n",
    "              'pop' : 7,\n",
    "              'reggae': 8,\n",
    "              'rock' : 9    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46c74773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data():\n",
    "    data = []\n",
    "    # Collect all images from the 10 genres\n",
    "    for genre in os.listdir(\"../Data/images_original\"):\n",
    "        for image in os.listdir(\"../Data/images_original/\" + genre):\n",
    "            image_path = \"../Data/images_original/\" + genre + \"/\" + image\n",
    "            grayscale_img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            grayscale_img = grayscale_img[35:-36:, 54:-43]\n",
    "            grayscale_img = torch.tensor(grayscale_img).to(dtype = torch.float32).clone().detach().requires_grad_(True)  #.requires_grad(True)\n",
    "            #grayscale_img = torch.tensor(grayscale_img, requires_grad=True)\n",
    "            # Splitting each image vertically into 5 different parts\n",
    "            for i in range(5):\n",
    "                # The data loader adds a dimension so I've removed a dimension from the image and class\n",
    "                data.append((grayscale_img[ : ,  (67*i):67*(i+1)].reshape(1,217,67), torch.tensor(class_dict.get(genre)))) #.reshape(1)))\n",
    "            \n",
    "    return data         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dfe6fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = collect_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10d0f684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4995"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "374b5cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a77e596",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = random.sample(data, 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1bb5f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fce583f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 217, 67])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(0.8 * len(data))\n",
    "test_size = len(data) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(data, [train_size, test_size])\n",
    "\n",
    "train_dataset[2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc8cfe41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fad1bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data in dataloader format\n",
    "train_loader = DataLoader(train_dataset, batch_size=25, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=25, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37be9e9d",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f5cfecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"C:/Users/bbste/Documents/LSE/ST311/ST311-Group-Project/Data/features_30_sec.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bf7710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f28e5ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea3237e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del raw_df['filename']\n",
    "del raw_df['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dfe0b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['label'] = raw_df['label'].map(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b77c775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = StandardScaler().fit_transform(raw_df.iloc[:, 0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e3e6f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df, columns = raw_df.columns.tolist()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fafd924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = raw_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d803d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = [(torch.tensor(list(df.loc[i][:-1])).clone().detach().requires_grad_(True).reshape(1,1,-1), torch.tensor(df['label'][i], dtype=torch.long)) for i in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "241b6d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(metadata))\n",
    "test_size = len(metadata) - train_size\n",
    "metadata_train_dataset, metadata_test_dataset = torch.utils.data.random_split(metadata, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12632211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data in dataloader format\n",
    "metadata_train_loader = DataLoader(metadata_train_dataset, batch_size=25, shuffle=True)\n",
    "metadata_test_loader = DataLoader(metadata_test_dataset, batch_size=25, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5c69cf",
   "metadata": {},
   "source": [
    "# Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c1ab2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Accuracy of the network on the test images: 45 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(27705, 25)             #(32 * 54 * 17 + 57, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        #self.fc2 = nn.Linear(512, 64)\n",
    "        #self.sig = nn.Sigmoid()\n",
    "        #self.fc3 = nn.Linear(64, 25)\n",
    "        #self.sig3 = nn.Sigmoid()\n",
    "        self.fc4 = nn.Linear(25, 10)\n",
    "        \n",
    "\n",
    "    def forward(self, x_image, x_metadata):\n",
    "        x_image = self.pool1(self.relu1(self.conv1(x_image)))\n",
    "        x_image = self.pool2(self.relu2(self.conv2(x_image)))\n",
    "        x_image = x_image.view(x_image.size(0), -1)\n",
    "        x_metadata = x_metadata.view(x_metadata.size(0), -1)\n",
    "        #print(x_metadata.shape)\n",
    "        x = torch.cat((x_image, x_metadata), dim=1)\n",
    "        #print(x.shape)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        #x = self.fc2(self.sig(x))\n",
    "        #x = self.fc3(self.sig(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Set up the dataloaders\n",
    "trainloader_image = train_loader\n",
    "testloader_image = test_loader\n",
    "trainloader_metadata = metadata_train_loader\n",
    "testloader_metadata = metadata_test_loader\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    running_loss = 0.0\n",
    "    for i, ((images, labels), (metadata, _)) in enumerate(zip(trainloader_image, trainloader_metadata)):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, metadata)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch+1, num_epochs, i+1, len(trainloader_image), running_loss/100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for (images, labels), (metadata, _) in zip(testloader_image, testloader_metadata):\n",
    "        #print(images.shape)\n",
    "        outputs = model(images, metadata)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82968615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
